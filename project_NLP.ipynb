{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833b77cd-8a3f-4294-803d-3b8554f2720c",
   "metadata": {},
   "source": [
    "## NLP. Классификация отзывов на фильмы. IMDB Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c09d01-89f4-4f4f-8a2b-d327de049f0f",
   "metadata": {},
   "source": [
    "Произведем загрузку набора данных в DataFrame pandas, изначально разделив на тренировочный и испытательный наборы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560290a2-1383-47d7-96f0-337fce6dec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "basepath = 'C:/dataset/aclImdb'\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in sorted(os.listdir(path)):\n",
    "            with open(os.path.join(path, file), \n",
    "                      'r', encoding='utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            match = re.search(r'_(\\d+)', file)\n",
    "            rate = match.group(1)    \n",
    "            if s == 'test':\n",
    "                df_test = pd.concat([df_test, pd.DataFrame({'review': pd.Series(txt), 'rate':pd.Series(int(rate)-1), 'assessment': pd.Series(labels[l])})], ignore_index=True)\n",
    "            else:\n",
    "                df_train = pd.concat([df_train, pd.DataFrame({'review': pd.Series(txt), 'rate':pd.Series(int(rate)-1), 'assessment': pd.Series(labels[l])})], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70803ef5-939f-4c10-ba7c-a56b8cb5b051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfda715-a162-457d-928d-6bf9f2656232",
   "metadata": {},
   "source": [
    "Для задачи классификации необходимо, чтобы метки начинались с 0, поэтому мы вычли из каждого рейтинга единицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e971b37-ea86-425d-ba17-47c41e3ce9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 9, 6, 2, 3, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['rate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90385921-be5b-4500-aa01-7ebbae0436ff",
   "metadata": {},
   "source": [
    "Для обучения модели перемешаем образцы, поскольку они отсортированы по assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86873af5-9a5e-4660-b54d-e38808c7b16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>Actually one particular person/character isn't...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>Rarely do I see a film that I am totally engro...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>The Farrelly brothers, Bobby and Peter, are at...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>Some illegal so-called asylum seeker comes to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23154</th>\n",
       "      <td>There really wasn't much of a story in this fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  assessment\n",
       "6806   Actually one particular person/character isn't...     8           1\n",
       "7136   Rarely do I see a film that I am totally engro...     8           1\n",
       "5098   The Farrelly brothers, Bobby and Peter, are at...     6           1\n",
       "14635  Some illegal so-called asylum seeker comes to ...     0           0\n",
       "23154  There really wasn't much of a story in this fi...     1           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.reindex(np.random.permutation(df_train.index))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97a86b-c0f1-4dc1-9304-22968c72d4fe",
   "metadata": {},
   "source": [
    "В основе нашей модели будет лежать логистическая регрессия, оптимальные гиперпараметры которой будут найдены с помощью решетчатого поиска. Вначале из текста убирается шум, а далее текст каждой рецензии будет преобразован в соответствии с моделью суммирования: создается словарь уникальных слов с отображением на число, а далее каждый отзыв преобразуется в вектор признаков, содержащий счетчик частоты появления каждого слова из словаря в каждом отзыве, а далее эти сырые частоты термов преобразуются в меры tf-idf. Все эти преобразования происходят с помощью функции TfidfVectorizer. Для удобства создадим pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2d4bdf-d267-4537-b7c0-94b1baeadf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Лучшие параметры: {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Правильность при перекрестной проверке 0.425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import re\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub(r'<[^>]*>', '', text)  # Удаляем HTML-теги\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower())  # Заменяем не-алфавитные символы на пробелы\n",
    "    return text\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=preprocessor, stop_words = 'english', ngram_range=(1, 1))\n",
    "\n",
    "param_grid = [{'clf__penalty': ['l2'], 'clf__C': [0.1, 1, 10]}]\n",
    "clf_pipe = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0, max_iter=200))])\n",
    "\n",
    "gs = GridSearchCV(clf_pipe, param_grid, scoring='accuracy', cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "X_train = df_train['review']\n",
    "y_train = df_train['rate']\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшие параметры:', gs.best_params_)\n",
    "print('Правильность при перекрестной проверке %.3f' % gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502d6f70-7f96-4cb6-a5ee-7d950584b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd06d7e-88e0-4861-8945-c24a6c23ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_test['review'],  df_test['rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754954db-d9f0-4601-a95e-9de644039503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на испытательном наборе: 0.418\n"
     ]
    }
   ],
   "source": [
    "print('Правильность на испытательном наборе: %.3f' % clf.score(X_test,y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32890b7-029a-4663-80bb-e60d4029f72d",
   "metadata": {},
   "source": [
    "Неплохо, учитывая, что оценка человека на фильм может легко варироваться в неком диапозоне. Проверим насколько наша модель правильно отличает плохой отзыв от хорошего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba01cb2a-03fc-4c3a-ae78-cb7faea33fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = clf.predict(X_test)\n",
    "predict_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca022f3-0021-403a-8923-3821068be2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_test = [int(x) for x in (predict_test>=5) ]\n",
    "assessment_train = [int(x) for x in (predict_train>=5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f44ed9-422a-4e1a-b348-7039b13dc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6ac91-86ca-4814-a032-0d58862c7cff",
   "metadata": {},
   "source": [
    "Правильность при классификации на плохой и хороший отзыв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a35b8381-a64e-4df2-92aa-effe987e24a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на испытательном наборе данных:  0.94212\n"
     ]
    }
   ],
   "source": [
    "print('Правильность на тренировочном наборе данных: ',accuracy_score(df_train['assessment'],assessment_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4a6cf6d-1d04-4c1c-b822-c523ea6ffb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на тренировочном наборе данных: 0.86848\n"
     ]
    }
   ],
   "source": [
    "print('Правильность на испытательном наборе данных:', accuracy_score(df_test['assessment'],assessment_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28826f69-d8f9-41e9-8dc6-1b70ed487a68",
   "metadata": {},
   "source": [
    "Можно было создать DL сеть с Embedding и LSTM слоями, но обучить такую модель было бы в разы сложнее, но не факт, что результат был бы намного лучше. \n",
    "Я думаю результат и так удовлетворителен. Целью ставилось создать модель и развернуть ее как сервис для оценки отзывов, что и было сделано. Если потре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b017465-08e2-4f2f-851a-fcc90c8e3618",
   "metadata": {},
   "source": [
    "При переходе на сайт необходимо подождать 1-2 минуты, пока он выйдет из \"спящего\" режима."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f909418-d3d1-40a9-80cb-4fe66f0a66fc",
   "metadata": {},
   "source": [
    "https://web-96q2.onrender.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
